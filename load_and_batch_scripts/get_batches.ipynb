{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dawnstear/desktop/tensorflow_update/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/dawnstear/desktop/tensorflow_update/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "next_batch() is a function specifically for the MNIST tutorial provided by tensorflow. \n",
    "How it works is it randomizes the training image and label pairs at the begining, and \n",
    "selects each subsequent 100 images each time the function is called. Once it reaches the \n",
    "end, the image-label pairs are randomized again, and the process is repeated. \n",
    "The entire dataset is only reshuffled and repeated once all the available pairs are used\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#np.random.seed(0)\n",
    "#tf.set_random_seed(0) # set random seed for tf only or for whole env?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(datamatrix,\n",
    "                batch_size=None,test=False,\n",
    "                test_size=0.2,SHUFFLE=True, init=[0]): # 0/None/False\n",
    "    \n",
    "    init = 1\n",
    "    n_cells, n_genes = np.shape(datamatrix)\n",
    "    assert batch_size < len(datamatrix)\n",
    "    \n",
    "    # Convert to np array\n",
    "    if type(datamatrix) is not np.ndarray: datamatrix = np.asarray(datamatrix)\n",
    "    assert type(datamatrix) == np.ndarray\n",
    "\n",
    "    if SHUFFLE and init:\n",
    "        datamatrix = shuffle(datamatrix)\n",
    "        \n",
    "    if batch_size is None:\n",
    "        batch_size = int(n_cells*0.1) # default batch size =1/10 of all samples\n",
    "    else: \n",
    "        batch_size = int(batch_size)\n",
    "        \n",
    "    # Convert input datamatrix to tensor\n",
    "    # X = tf.convert_to_tensor(datamatrix, dtype=tf.float32) convert to tensor at the end\n",
    "    \n",
    "    # how to tell if fcn has been called after first call? -only shuffle once\n",
    "    X_train, X_test, y_trn, y_tst = train_test_split(datamatrix,\n",
    "                                                     np.zeros(n_cells),\n",
    "                                                     test_size=test_size,\n",
    "                                                     shuffle=True)#,random_state=144)\n",
    "    X_train = list(X_train)\n",
    "    \n",
    "    #while not X_train: #check if list is emtpy\n",
    "    batch = [X_train.pop() for idx in range(batch_size)]\n",
    "    return batch\n",
    "    \n",
    "    # while data is not empty:   \n",
    "    #if test is False:\n",
    "    #    return X_train[1:batch_size+1,:] # shuffle again?\n",
    "    #else:\n",
    "    #    return X_test[1:batch_size+1,:] # pop data out each time                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = np.random.rand(18,5)\n",
    "X = np.array([[1,1,1,1,1,1,1,1],[2,2,2,2,2,2,2,2,],\n",
    "              [3,3,3,3,3,3,3,3],[4,4,4,4,4,4,4,4],[5,5,5,5,5,5,5,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  =  pd.read_csv('/Users/dawnstear/desktop/chop_cellpred/data.csv')\n",
    "scdata = data.drop(['Labels','TYPE'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([360.        ,   1.78674693,   0.        , ...,   0.        ,\n",
      "         2.20717491,   0.        ]), array([1032.        ,    0.        ,    0.        , ...,    4.86398971,\n",
      "          0.        ,    0.        ]), array([1006.        ,    0.        ,    0.        , ...,    3.91681152,\n",
      "          3.11484775,    0.        ]), array([429.,   0.,   0., ...,   0.,   0.,   0.])]\n"
     ]
    }
   ],
   "source": [
    "c = get_batches(scdata,batch_size=4) # convert to tensor\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
