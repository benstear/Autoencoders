#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Thu Jun 21 19:19:14 2018

@author: dawnstear
"""

# Auto Encoder NN from ML book
from functools import partial
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data

tf.logging.set_verbosity(tf.logging.INFO)

mnist = input_data.read_data_sets('/Users/dawnstear/desktop/mnist/')  

n_inputs = 28*28 # mnist (784)
n_hidden1 = 300
n_hidden2 = 150
n_hidden3 = n_hidden1
n_outputs = n_inputs

lr = 0.01
l2reg = 0.0001
#_____________________________________
validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(
         mnist.test.images[2:60],
         mnist.test.labels[2:60],
         every_n_steps=50)
  #_________________________________________

X = tf.placeholder(tf.float32, shape=[None, n_inputs])

he_init = tf.contrib.layers.variance_scaling_initializer()
l2_regularizer = tf.contrib.layers.l2_regularizer(l2reg)
my_dense_layer = partial(tf.layers.dense, 
                         activation=tf.nn.elu,
                         kernel_initializer = he_init,
                         kernel_regularizer=l2_regularizer)

hidden1 = my_dense_layer(X, n_hidden1)
hidden2 = my_dense_layer(hidden1, n_hidden2) #codings are here
hidden3 = my_dense_layer(hidden2, n_hidden3)
outputs = my_dense_layer(hidden3, n_outputs)  # create the path that the tensors will flow through

reconstruction_loss = tf.reduce_mean(tf.square(outputs-X)) # normal NN would be outputs - y ?

reg_loss = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)
loss = tf.add_n([reconstruction_loss] + reg_loss)   

optimizer = tf.train.AdamOptimizer(lr)
training_op = optimizer.minimize(loss)

saver = tf.train.Saver()

init = tf.global_variables_initializer()

n_epochs = 5
batch_size = 150

with tf.Session() as sess:
    init.run()
    for epoch in range(n_epochs):
        n_batches = mnist.train.num_examples // batch_size
        for iteration in range(n_batches):
            X_batch, y_batch = mnist.train.next_batch(batch_size)
            sess.run(training_op, feed_dict={X: X_batch})
            
        print(tf.trainable_variables())
        #tf.global_variables            



